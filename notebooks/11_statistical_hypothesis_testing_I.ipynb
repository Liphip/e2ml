{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Statistical Hypothesis Testing I\n",
    "\n",
    "In this notebook, we will implement and apply **statistical hypothesis tests** to make inferences about populations based on sample data.\n",
    "\n",
    "At the start, we clarify common misconceptions in statistical hypothesis testing.\n",
    "\n",
    "Subsequently, we will implement the one-sample $z$-test and the one-sample $t$-test.\n",
    "\n",
    "Finally, we will apply one of the tests to a concrete example.\n",
    "\n",
    "### **Table of Contents**\n",
    "1. [Clarification of Misconceptions](#misconceptions)\n",
    "2. [One-samples Tests](#one-sample-tests)\n",
    "3. [Example](#example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Clarification of Misconceptions** <a class=\"anchor\" id=\"misconeptions\"></a>\n",
    "Statistical hypothesis testing can often cause confusion and thus misconceptions, which we would like to clarify below.\n",
    "\n",
    "#### **Questions:**\n",
    "1. (a) Is the $p$-value the probability that the null hypothesis $H_0$ is true given the data?\n",
    "   \n",
    "   _Answer:_<br/>\n",
    "      No, the $p$-value is the probability of observing a test statistic at least as extreme as the one observed, given that the null hypothesis $H_0$ is true.\n",
    "\n",
    "   (b) Are hypothesis tests carried out to decide if the null hypothesis is true or false?\n",
    "\n",
    "   _Answer:_<br/>\n",
    "      No, the null hypothesis is assumed to be true. The hypothesis test is carried out to decide if the data is consistent with the null hypothesis or not.\n",
    "   \n",
    "   (c) Are hypothesis tests carried out to establish the test statistic?\n",
    "   \n",
    "   _Answer:_<br/>\n",
    "      No, the test statistic is calculated from the data. The hypothesis test is carried out to determine the $p$-value.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. One-sample Tests** <a class=\"anchor\" id=\"one-sample-tests\"></a>\n",
    "\n",
    "We implement the function [`z_test_one_sample`](../e2ml/evaluation/_one_sample_tests.py) in the [`e2ml.evaluation`](../e2ml/evaluation) subpackage. Once, the implementation has been completed, we check it for varying types of tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from e2ml.evaluation import z_test_one_sample\n",
    "sigma = 0.5\n",
    "mu_0 = 2\n",
    "sample_data = np.round(stats.norm.rvs(loc=2, scale=sigma, size=10, random_state=50), 1)\n",
    "z_statistic, p = z_test_one_sample(sample_data=sample_data, mu_0=mu_0, sigma=sigma, test_type=\"right-tail\")\n",
    "assert np.round(z_statistic, 4) == -1.5811 , 'The z-test statistic must be ca. 4.590.' \n",
    "assert np.round(p, 4) == 0.9431, 'The p-value must be ca. 0.0007 for the one-sided right-tail test.' \n",
    "z_statistic, p = z_test_one_sample(sample_data=sample_data, mu_0=mu_0, sigma=sigma, test_type=\"left-tail\")\n",
    "assert np.round(z_statistic, 4) == -1.5811 , 'The z-test statistic must be ca. 4.590.' \n",
    "assert np.round(p, 4) == 0.0569, 'The p-value must be ca. 0.9993 for the one-sided left-tail test.' \n",
    "z_statistic, p = z_test_one_sample(sample_data=sample_data, mu_0=mu_0, sigma=sigma, test_type=\"two-sided\")\n",
    "assert np.round(z_statistic, 4) == -1.5811 , 'The z-test statistic must be ca. 4.590.' \n",
    "assert np.round(p, 4) == 0.1138, 'The p-value must be ca. 0.0014 for the two-sided test.' "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement the function [`t_test_one_sample`](../e2ml/evaluation/_one_sample_tests.py) in the [`e2ml.evaluation`](../e2ml/evaluation) subpackage. Once, the implementation has been completed, we check it for varying types of tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from e2ml.evaluation import t_test_one_sample\n",
    "sample_data = np.round(stats.norm.rvs(loc=13.5, scale=0.25, size=10, random_state=1), 1)\n",
    "t_statistic, p = t_test_one_sample(sample_data=sample_data, mu_0=13, test_type=\"right-tail\")\n",
    "assert np.round(t_statistic, 4) == 4.5898 , 'The t-test statistic must be ca. 4.590.' \n",
    "assert np.round(p, 4) == 0.0007, 'The p-value must be ca. 0.0007 for the one-sided right-tail test.' \n",
    "t_statistic, p = t_test_one_sample(sample_data=sample_data, mu_0=13, test_type=\"left-tail\")\n",
    "assert np.round(t_statistic, 4) == 4.5898 , 'The t-test statistic must be ca. 4.590.' \n",
    "assert np.round(p, 4) == 0.9993, 'The p-value must be ca. 0.9993 for the one-sided left-tail test.' \n",
    "t_statistic, p = t_test_one_sample(sample_data=sample_data, mu_0=13, test_type=\"two-sided\")\n",
    "assert np.round(t_statistic, 4) == 4.5898 , 'The t-test statistic must be ca. 4.590.' \n",
    "assert np.round(p, 4) == 0.0013, 'The p-value must be ca. 0.0014 for the two-sided test.' "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Example** <a class=\"anchor\" id=\"example\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us assume we have access to the follwing *identically and independently distributed* (i.i.d.) heart rate measurements $[\\mathrm{beats/min}]$ of 40 patients in an *intensive care unit* (ICU):\n",
    "\n",
    "$124, 111,  96, 104,  89, 106,  94,  48, 117,  61, 117, 104,  72,\n",
    "86, 126, 103,  97,  49,  78,  52, 119, 107, 131, 112,  78, 132,\n",
    "80, 139,  87,  44,  40,  60,  40,  80,  41, 103, 102,  44, 115,\n",
    "103.$\n",
    "\n",
    "#### **Questions:**\n",
    "3. (a) Are heart rates from ICU patients unusual given normal heart rate has mean of 72 beats/min with a significance of .01? Perform a statistical hypothesis test by following the steps presented in the lecture and by using Python.\n",
    "\n",
    "   _Answer:_<br/>\n",
    "\n",
    "   Step 1: Define null and alternative hypothesis\n",
    "      H0: heart rate is normal\n",
    "      H1: heart rate is not normal\n",
    "\n",
    "   Step 2: Define test statistic\n",
    "      Median of the sample\n",
    "\n",
    "   Step 3: Find sampling distribution of test statistic under H0\n",
    "      We assume that the heart rate is normally distributed with mean 72 beats/min and standard deviation 10 beats/min.\n",
    "\n",
    "   Step 4: Choose significance level\n",
    "      alpha = 0.01\n",
    "\n",
    "   Step 5: Evaluate test statistic\n",
    "      The median of the sample is 96.5 beats/min.\n",
    "\n",
    "   Step 6: Calculate p-value\n",
    "      p-value = t_test_one_sample(sample, 72, 10, alternative='two-sided')\n",
    "\n",
    "   Step 7: Decide\n",
    "      if p-value < alpha: reject H0\n",
    "      else: do not reject H0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reject the null hypothesis at the 1.0% significance level. With a p-value of 0.0004 the data provides enough evidence to reject the null hypothesis.\n"
     ]
    }
   ],
   "source": [
    "# Perform hypothesis test\n",
    "X_bar = np.array([124, 111,  96, 104,  89, 106,  94,  48, 117,  61, 117, 104,  72,\n",
    "86, 126, 103,  97,  49,  78,  52, 119, 107, 131, 112,  78, 132,\n",
    "80, 139,  87,  44,  40,  60,  40,  80,  41, 103, 102,  44, 115,\n",
    "103])\n",
    "\n",
    "# 1. Define null and alternative hypotheses\n",
    "# H_0: mu_0 = 72\n",
    "# H_1: mu_0 != 72\n",
    "mu_0 = 72\n",
    "\n",
    "# 2. Select appropriate test statistic s\n",
    "s_n = lambda x_n: 1/len(X_bar) * sum(X_bar)\n",
    "\n",
    "# 3. Find sampling distribution for s under H_0\n",
    "# s ~ N(mu, sigma/sqrt(n))\n",
    "\n",
    "# 4. Choose significance level alpha\n",
    "alpha = 0.01\n",
    "\n",
    "# 5. Evaluate the test statistic s for observed data\n",
    "s_bar = s_n(X_bar)\n",
    "\n",
    "# 6. Compute p-value\n",
    "t_statistic, p = t_test_one_sample(sample_data=X_bar, mu_0=mu_0, test_type=\"two-sided\")\n",
    "\n",
    "# 7. Make decision\n",
    "if p < alpha:\n",
    "    print(f\"Reject the null hypothesis at the {alpha*100}% significance level. With a p-value of {np.round(p, 4)} the data provides enough evidence to reject the null hypothesis.\")\n",
    "else:\n",
    "    print(f\"Do not reject the null hypothesis at the {alpha*100}% significance level. With a p-value of {np.round(p, 4)} the data does not provide enough evidence to reject the null hypothesis.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P-Hacking:\n",
    "    When significance level not given, it is tempting to choose the significance level that gives the desired result. Alternatively, one can perform multiple tests and choose the one that gives the desired result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
